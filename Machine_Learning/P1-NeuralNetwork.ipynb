{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SWCON253] Machine Learning\n",
    "Instructor: Eunseop Shin (kairos9603@khu.ac.kr)\n",
    "\n",
    "Professor: Hui Yong Kim (hykim.v@khu.ac.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P1.A:  Pure Python만을 이용하여 Perceptron 구현 (5점)\n",
    "\n",
    "### 학습목표\n",
    "- Perceptron Python class를 직접 구현하면서 NN의 작동방법을 이해한다.\n",
    "- 머신러닝 모델의 데이터 준비, 개발, 학습, 검증, 시각화 과정을 이해하고 설명 할 수 있다.\n",
    "\n",
    "### 실습내용\n",
    "Frank Rosenblatt의 classic perceptorn binary classication(0 또는 1을 구분하는)을 구현합니다. <br>\n",
    "여러분은 \"Pure\" 혹은 \"vanila\" Python 함수만을 사용하여 구현해야합니다. 그러므로 시각화를 위한 matplotlib 이외의 패키지는 사용하지마세요.\n",
    "\n",
    "실습은 다음 순서로 진행됩니다.\n",
    "- 0) 실습에서 사용되는 패키지 import\n",
    "- 1) 주어진 데이터셋 loading\n",
    "- 2) Perceptron Model 구현 **<직접 구현>**\n",
    "- 3) Perceptron Model 학습\n",
    "- 4) Perceptron Model 검증\n",
    "- 5) Decision Boundary 시각화\n",
    "- 6) Discussion\n",
    "\n",
    "**이번 실습에서 여러분은 `2) Perceptron Model 구현` 부분의 코드를 직접 작성합니다.**\n",
    "\n",
    "앞으로 대부분의 실습도 위와 같은 순서로 진행됩니다. 이번 실습을 통해 각 부분의 코드를 이해하고 다음 실습에 참고하도록합니다.\n",
    "\n",
    "\n",
    "### 점수\n",
    "- Perceptron model 구현: 각 함수별로 1점\n",
    "\n",
    "`.ipynb 파일과 함께 .html 파일 (File -> export as -> HTML)도 함께 제출하세요. 하나만 제출할시 감점이 있습니다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Imports\n",
    "**수정하지 마세요.** HW1에서는 \"pure\" python으로만 코드를 작성합니다. `matplotlib`이외의 패키지는 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Loading the Dataset\n",
    "**수정하지 마세요.** 코드를 실행시켜 실습코드와 같이 첨부된 dataset.csv파일을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일을 읽기\n",
    "X, y = [], []\n",
    "\n",
    "with open('./dataset.csv', 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            values = line.split(',')\n",
    "        else:\n",
    "            continue\n",
    "        X.append([float(i) for i in values[:2]])\n",
    "        y.append(int(values[-1]))\n",
    "        \n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Split & Visualization\n",
    "Load 된 데이터셋을 모델 학습과 검증을 위해 Trainset과 Testset으로 랜덤 샘플링하여 나누고 데이터셋이 어떤 분포로 생겼는지 시각화하여 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# 랜덤시드 설정\n",
    "random.seed(123)\n",
    "\n",
    "# 데이터 랜덤 셔플\n",
    "idx = list(range(len(X)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "# 앞 80개 까지는 학습용으로 뒤 20개는 테스트용으로 split\n",
    "X_train = [X[i] for i in idx[:80]]\n",
    "y_train = [y[i] for i in idx[:80]]\n",
    "X_test = [X[i] for i in idx[80:]]\n",
    "y_test = [y[i] for i in idx[80:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 클래스 별로 데이터를 시각화 하여 분포를 살펴보기\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_train) if y_train[idx] == 0], \n",
    "            [i[1] for idx, i in enumerate(X_train) if y_train[idx] == 0],\n",
    "            label='class 0', marker='o')\n",
    "\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_train) if y_train[idx] == 1], \n",
    "            [i[1] for idx, i in enumerate(X_train) if y_train[idx] == 1],\n",
    "            label='class 1', marker='s')\n",
    "\n",
    "plt.title('Training set')\n",
    "plt.xlabel('feature 1')\n",
    "plt.ylabel('feature 2')\n",
    "plt.xlim([0.0, 7])\n",
    "plt.ylim([-0.8, 0.8])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Perceptron model 구현\n",
    "이 부분에서는 직접 `Perceptron model`을 구현해 봅니다.\n",
    "\n",
    "Perceptron model은 생성자, forward, backward, train, evaluation 다섯개 함수로 이루어져 있습니다.\n",
    "- `__init__` 생성자에서는 Perceptron의 weights와 bias를 초기화합니다.\n",
    "- `forward`에서는 input을 Perceptron의 가중치를 이용해서 예측을 수행합니다.\n",
    "- `backward`에서는 Perceptron의 가중치를 학습하기 위해 에러를 계산합니다.\n",
    "- `train`에서는 Perceptron을 학습하는 과정으로 `forward`와 `backward`를 차례로 반복하여 Perceptron의 가중치를 업데이트 합니다.\n",
    "- `evaluation`에서는 들어온 input data를 학습된 가중치를 이용하여 예측하고 결과를 반환합니다.\n",
    "\n",
    "아래 `# <your code>` 부분을 채워 넣어서 Perceptron class를 직접 작성하여 구현하세요.\n",
    "\n",
    "**세부 구현 사항:**\n",
    "- weights는 랜덤으로 초기화, bias는 0으로 초기화한다.\n",
    "- activation은 0.이상은 1., 이하는 0.으로 하도록한다.\n",
    "- 설명되지 않은 사항은 자유롭게 작성하고 주석으로 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptorn\n",
    "![Perceptron](https://www.researchgate.net/profile/Daniel-Alvarez-34/publication/315788933/figure/fig3/AS:479799241121795@1491404461957/Scheme-of-a-perceptron-A-nonlinear-activation-function-BULLET-is-applied-to-the.png)\n",
    "출처: https://www.researchgate.net/figure/Scheme-of-a-perceptron-A-nonlinear-activation-function-BULLET-is-applied-to-the_fig3_315788933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Perceptron():\n",
    "    def __init__(self, num_features):\n",
    "        self.weights = [random.randint(1, 100)/100, random.randint(1, 100)/100] # <your code> initialization\n",
    "        self.bias = 0# <your code> initialization\n",
    "\n",
    "    def forward(self, x):\n",
    "        linear = self.weights[0] * x[0] + self.weights[1] + x[1] + self.bias# <your code> compute weighted sum\n",
    "        prediction = 1 if linear >= 0 else 0 # <your code> apply activation\n",
    "        return prediction\n",
    "        \n",
    "    def backward(self, x, y):\n",
    "        # print(x,y)\n",
    "        # <your code> to compute the prediction error\n",
    "        diff = y - self.weights[0] * x[0] - self.weights[1] * x[1] - self.bias\n",
    "        # print(diff)\n",
    "        errors = [-diff * self.weights[i] for i in range(2)]\n",
    "        errors.append(-diff)\n",
    "        return errors\n",
    "        \n",
    "    def train(self, x, y, epochs):\n",
    "        # epochs 만큼 학습\n",
    "        for e in range(epochs):\n",
    "            # 데이터 하나씩 학습\n",
    "            # print(self.weights)\n",
    "            for i in range(len(y)):\n",
    "                # <your code> to update the weights and bias\n",
    "                print(\"weights\", self.weights)\n",
    "                for j in range(len(self.weights)):\n",
    "                    self.weights[j] += self.backward(x[i], y[i])[j]\n",
    "                self.bias += self.backward(x[i], y[i])[-1]\n",
    "                print(self.weights, self.bias)\n",
    "    def evaluate(self, x, y):\n",
    "        # <your code> to compute the prediction accuracy\n",
    "        total = len(x)\n",
    "        count = 0\n",
    "        for i in range(len(x)):\n",
    "            if self.forward(x[i]) == y[i]:\n",
    "                count += 1\n",
    "\n",
    "        accuracy = round(count / total,4)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Perceptron 학습\n",
    "\n",
    "작성한 Perceptorn을 Trainset을 이용해 5 epoch 학습하고 학습된 weight, bias를 print합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights [0.12, 0.11]\n",
      "[0.04775999999999998, 0.0159676] -0.83603352\n",
      "weights [0.04775999999999998, 0.0159676]\n",
      "[0.011633189759999996, 0.00296635060929884] -1.6528606662621401\n",
      "weights [0.011633189759999996, 0.00296635060929884]\n",
      "[-0.01882204846549099, -0.00507046262925437] -4.362187477920753\n",
      "weights [-0.01882204846549099, -0.00507046262925437]\n",
      "[0.08357010040540665, 0.020436207100121284] -9.37987645066982\n",
      "weights [0.08357010040540665, 0.020436207100121284]\n",
      "[-0.7597596682459726, -0.24783546219156133] -22.3461864297102\n",
      "weights [-0.7597596682459726, -0.24783546219156133]\n",
      "[19.285435343583153, -13.083893482653439] 25.595656935757873\n",
      "weights [19.285435343583153, -13.083893482653439]\n",
      "[1020.3351304815583, -20338.671334460574] -2486.040257298262\n",
      "weights [1020.3351304815583, -20338.671334460574]\n",
      "[-1793952.625360857, 171620375399.0413] 34315638529.38858\n",
      "weights [-1793952.625360857, 171620375399.0413]\n",
      "[-1.8470218241107283e+17, -9.826582176478853e+28] -3.930632870648798e+28\n",
      "weights [-1.8470218241107283e+17, -9.826582176478853e+28]\n",
      "[3.629982347517003e+45, -1.4268127934817379e+75] 2.8536255869634753e+74\n",
      "weights [3.629982347517003e+45, -1.4268127934817379e+75]\n",
      "[-1.8228614794417598e+104, 4.941675951263846e+179] 9.883351902527692e+178\n",
      "weights [-1.8228614794417598e+104, 4.941675951263846e+179]\n",
      "[-1.801598147088516e+283, -inf] nan\n",
      "weights [-1.801598147088516e+283, -inf]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "weights [nan, nan]\n",
      "[nan, nan] nan\n",
      "[nan, nan]\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(num_features=2)  # 위에서 구현한 Perceptron 모델 정의\n",
    "ppn.train(X_train, y_train, 5)    # 5 epoch 학습\n",
    "\n",
    "# 학습된 모델의 weight, bias 출력\n",
    "print(ppn.weights)\n",
    "print(ppn.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 모델 검증\n",
    "Training set과 Test set각각에서 모델의 accuracy를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset에서 성능 검증\n",
    "train_acc = ppn.evaluate(X_train, y_train)\n",
    "print('Train set accuracy: %.2f%%' % (train_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset에서 성능 검증\n",
    "test_acc = ppn.evaluate(X_test, y_test)\n",
    "print('Test set accuracy: %.2f%%' % (test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Decision Boundary\n",
    "train 데이터셋과 test 데이터셋 각각을 이용하여 2개의 scatter plot을 그리고 그 위에 학습된 가중치를 이용하여 결정경계를 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train 데이터셋에서 Decision Boundary 시각화\n",
    "# 그래프로 표현\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_train) if y_train[idx] == 0], \n",
    "            [i[1] for idx, i in enumerate(X_train) if y_train[idx] == 0],\n",
    "            label='class 0', marker='o')\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_train) if y_train[idx] == 1], \n",
    "            [i[1] for idx, i in enumerate(X_train) if y_train[idx] == 1],\n",
    "            label='class 1', marker='s')\n",
    "# Perscptron의 Weight와 Bias를 그래프로 표현\n",
    "plt.plot([0, 7], [-ppn.bias/ppn.weights[1], -(7*ppn.weights[0] + ppn.bias)/ppn.weights[1]])\n",
    "\n",
    "# 그래프로 표현\n",
    "plt.title('Training set')\n",
    "plt.xlabel('feature 1')\n",
    "plt.ylabel('feature 2')\n",
    "plt.xlim([0.0, 7])\n",
    "plt.ylim([-0.8, 0.8])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "### Test 데이터셋에서 Decision Boundary 시각화\n",
    "# 그래프로 표현\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_test) if y_test[idx] == 0], \n",
    "            [i[1] for idx, i in enumerate(X_test) if y_test[idx] == 0],\n",
    "            label='class 0', marker='o')\n",
    "\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_test) if y_test[idx] == 1], \n",
    "            [i[1] for idx, i in enumerate(X_test) if y_test[idx] == 1],\n",
    "            label='class 1', marker='s')\n",
    "# Perscptron의 Weight와 Bias를 그래프로 표현\n",
    "plt.plot([0, 7], [-ppn.bias/ppn.weights[1], -(7*ppn.weights[0] + ppn.bias)/ppn.weights[1]])\n",
    "\n",
    "# 그래프로 표현\n",
    "plt.title('Test set')\n",
    "plt.xlabel('feature 1')\n",
    "plt.ylabel('feature 2')\n",
    "plt.xlim([0.0, 7])\n",
    "plt.ylim([-0.8, 0.8])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Discussion\n",
    "\n",
    "**1) 예시에서 사용된 activation 함수 이외의 어떤 함수가 있는지 찾아보고 설명해보세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) 단층 Perceptron 으로 풀 수 없는 문제는 어떤것이 있는지 왜 그런지 설명해보세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) 구현하면서 든 질문에 대해 적어보세요. 그리고 질문에 답할 수 있다면 스스로 답해보세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P1.B:  Deep Learning Framwork: Pytorh를 이용하여 MLP 구현 (5점)\n",
    "\n",
    "### 학습목표\n",
    "- pytorch를 사용하여 구현된 MLP 구조를 이해하고 수정할수 있다.\n",
    "- Fashinon-MNIST 문제를 스스로 해결하면서 딥러닝 학습과정을 이해하고 하이퍼파라미터를 튜닝을 할 수 있다.\n",
    "\n",
    "### 실습내용\n",
    "pytorch를 사용하여 구현 되어 있는 MLP를 통해 Fashion-MNIST 데이터셋을 분류하는 classfier를 학습합니다.\n",
    "\n",
    "실습은 다음 순서로 진행됩니다.\n",
    "- 1) Fashon-MNIST 데이터셋 설명\n",
    "- 2) Data loading\n",
    "- 3) Multilayer Perceptron Model\n",
    "- 4) Training\n",
    "- 5) Evaluation\n",
    "- 6) Discussion\n",
    "\n",
    "아래 코드에는 2개의 퍼셉트론은 이용한 MLP 모델이 정의 되어 있습니다.\n",
    "실습을 시작하기전에 이 노트북 파일을 읽고 모든 셀을 실행해하여 올바르게 작동하는지 확인하세요.<br>\n",
    "이후에 아키텍쳐를 마음껏 변경하여 최고의 성능이 나오도록 수정해 보세요.\n",
    "\n",
    "다음은 변경 가능한 부분입니다.\n",
    "- activation 함수 (logistic sigmoid, tanh, relu, leaky relu, ...)\n",
    "- learning rate\n",
    "- hidden layers 갯수\n",
    "- minibatch size\n",
    "\n",
    "그러나 다음 사항은 변경하지 마세요.\n",
    "- 가중치 초기화 방법\n",
    "- 랜덤시드\n",
    "- 최적화 방법, 학습 방법\n",
    "- epochs\n",
    "\n",
    "(Optional) layer를 추가하여 2개 이상의 hidden layer를 구성할 수 있습니다. <br>\n",
    "이 사항은 필수가 아닙니다. 하지만 구현하여 기준점수에 도달한 경우 **추가점수 +2점**이 있습니다.\n",
    "\n",
    "수정가능한 셀은 아래 주석으로 확실하게 하이라이트되어 표시되어 있습니다.\n",
    "\n",
    "```\n",
    "############################################################\n",
    "# 변경 가능한 셀\n",
    "############################################################\n",
    "```\n",
    "\n",
    "### 점수\n",
    "**Test set 기준**\n",
    "\n",
    "- 정확도 85% 이상 2점\n",
    "- 정확도 86% 이상 3점\n",
    "- 정확도 87% 이상 4점\n",
    "- 정확도 88% 이상 5점\n",
    "\n",
    "`.ipynb 파일과 함께 .html 파일 (File -> export as -> HTML)도 함께 제출하세요. 하나만 제출할시 감점이 있습니다.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 부분은 절대 변경하지 마세요.\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 데이터셋은 기존의 MNIST와 비슷하게 10개의 클래스로 이루어진 데이터셋입니다. 또한 흑백의 28x28크기, 60k개의 학습용 이미지와 10k개의 테스트용 이미지로 구성 되어 있는것과 같이 MNIST와 대부분 비슷한 구조로 이뤄져 있습니다. \n",
    "\n",
    "아래는 데이터셋의 샘플 이미지 입니다.\n",
    "\n",
    "![](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)\n",
    "\n",
    "출처: https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋의 10개의 클래스는 다음과 같습니다.\n",
    "\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 데이터 로딩시 데이터 Transform\n",
    "# Random Flip, Random Crop 등을 사용하여 Data augmentation을 수행하고 이를 통해 좋은 성능을 얻을 수 있습니다.\n",
    "# 하지만, 이번 실습에서는 사용하지 않습니다.\n",
    "custom_train_transform = transforms.Compose([  \n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 데이터 로딩시 데이터 Transform\n",
    "# Testset의 Trainsform은 Training set 과 다르게 랜덤하게 변경되면 안됩니다.\n",
    "# 이번 실습에서는 사용하지 않습니다.\n",
    "custom_test_transform = transforms.Compose([\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 변경 가능한 셀\n",
    "############################################################\n",
    "\n",
    "BATCH_SIZE = 64 # 60000을 사용하면 Full-Batch 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(\".\", train=True, download=True, transform=custom_train_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = FashionMNIST(\".\", train=False, download=True, transform=custom_test_transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 셀은 데이터셋이 잘 Load 되었는지 확인하는 테스트용 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        \n",
    "        print('break minibatch for-loop')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Multilayer Perceptron Model\n",
    "\n",
    "아래 셀은 MLP모델을 정의하는 부분입니다. 이 과제에서 메인 부분입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 변경 가능한 셀\n",
    "############################################################\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_hidden_1, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        ### (optional)레이어 추가 가능\n",
    "        self.linear_1 = torch.nn.Linear(num_features, num_hidden_1)\n",
    "        self.linear_out = torch.nn.Linear(num_hidden_1, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ### activation 함수 변경 가능\n",
    "        ### (optional)레이어간의 연결 추가, 변경 가능\n",
    "        out = self.linear_1(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        logits = self.linear_out(out)\n",
    "        probas = torch.sigmoid(logits)\n",
    "        return logits, probas\n",
    "\n",
    "    \n",
    "#################################\n",
    "### Model 초기화\n",
    "#################################\n",
    "\n",
    "# random seed는 무작위 가중치 초기화가 항상 같도록 해줍니다.\n",
    "# 초기화된 가중치에 따라 같은 네트워크도 서로 다른 성능을 낼 수 있어서 \n",
    "# 실제 사용시에는 좋은 성능을 얻기 위해 여러가지 무작위 가중치를 시도해 볼 수 있습니다.\n",
    "# 그러나 이 과제에서는 변경하지 않습니다.\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "### 모델의 hidden_layer갯수(num_hidden_1`를 변경하고싶거나, \n",
    "### (optional)레이어를 추가하였다면,\n",
    "### 이부분을 알맞게 수정하세요.\n",
    "model = MLP(num_features=28*28,\n",
    "            num_hidden_1=10,\n",
    "            num_classes=10)\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 변경 가능한 셀\n",
    "############################################################\n",
    "\n",
    "### Optimizer는 가중치를 업데이트하는 방법을 바꾸어 더 빠르게 좋은 성능을 낼 수 있도록합니다.\n",
    "### 이 과제에서는 optimizer를 변경하지 않습니다. \n",
    "### 그러나 Learning Rate(lr)는 변경이 가능합니다.\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_and_loss(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    cross_entropy = 0.\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.view(-1, 28*28).to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        cross_entropy += F.cross_entropy(logits, targets).item()\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100, cross_entropy/num_examples\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "train_acc_lst, test_acc_lst = [], []\n",
    "train_loss_lst, test_loss_lst = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "    \n",
    "        ### PREPARE MINIBATCH\n",
    "        features = features.view(-1, 28*28).to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 40:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "    # 매 Epoch마다 evaluation을 진행합니다. \n",
    "    # Epoch마다 Loss를 기록하여 학습과정을 살펴보고 Underfitting, Overfitting 여부를 확인합니다.\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # Gradient 계산이 안되도록\n",
    "        train_acc, train_loss = compute_accuracy_and_loss(model, train_loader, device=DEVICE) # train acc, loss 계산\n",
    "        test_acc, test_loss = compute_accuracy_and_loss(model, test_loader, device=DEVICE)    # test acc, loss 계산\n",
    "        \n",
    "        # list에 train, test의  acc, loss 추가\n",
    "        train_acc_lst.append(train_acc)\n",
    "        test_acc_lst.append(test_acc)\n",
    "        train_loss_lst.append(train_loss)\n",
    "        test_loss_lst.append(test_loss)\n",
    "        \n",
    "        # 로깅\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Test Acc.: {test_acc:.2f}%')\n",
    "    \n",
    "    # 1 epoch 학습 소요시간\n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "\n",
    "# 총 학습 소요시간\n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Evaluation\n",
    "\n",
    "테스트 데이터와 학습 데이터의 Loss변화를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, NUM_EPOCHS+1), train_loss_lst, label='Training loss')\n",
    "plt.plot(range(1, NUM_EPOCHS+1), test_loss_lst, label='Test loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, NUM_EPOCHS+1), train_acc_lst, label='Training accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS+1), test_acc_lst, label='Test accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    test_acc, test_loss = compute_accuracy_and_loss(model, test_loader, DEVICE)\n",
    "    print(f'Test accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) 학습, 테스트 정확도는 얼마인가요? (위 숫자를 복사하세요.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training:  ???%\n",
    "- Test ???%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) overfitting을 경험했나요? 만약 그랬다면 왜 그랬을지 적어보고, overfitting을 방지하기위한 간단한 방법은 무엇일까요?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[제안하는 방법 적기]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들면, \n",
    "\n",
    "- batch size를 256으로 변경\n",
    "- 두개의 hidden layers의 activation을 relu로 변경\n",
    "- learning rate를 0.2로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) 만약 테스트셋의 정확도가 85%에서 88%로 3% 향상되었다고 하면 얼마나 많은 이미지를 더 맞추게 된것일까요?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[간단한 계산식 적기]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) 구현하면서 든 질문에 대해 적어보세요. 그리고 질문에 답할 수 있다면 스스로 답해보세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}